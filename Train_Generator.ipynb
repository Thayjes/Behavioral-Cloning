{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt \n",
    "# Here we will define the function for preprocessing and augmentation\n",
    "def shadow_augmentation(image):\n",
    "    # Let us randomly define the quadrilateral where we want to apply the shadow \n",
    "    pt1 = np.array([np.random.choice([0, image.shape[1]]), 0])\n",
    "    pt2 = np.array([pt1[0], image.shape[0]])\n",
    "    pt3 = np.array([np.random.randint(0, image.shape[0]//2), image.shape[0]])\n",
    "    pt4 = np.array([np.random.randint(0, image.shape[0]//2), 0])\n",
    "    pts = np.array([pt1, pt2, pt3, pt4])\n",
    "    #print(pts)\n",
    "    # Convert the image to Hue, Lightness, Saturation color model.\n",
    "    image_HLS = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    # Initialize the mask\n",
    "    shadow_mask = 0*image_HLS[:, :, 1]\n",
    "    # Now fill the quadrilateral as defined before\n",
    "    shadow_mask = cv2.fillConvexPoly(shadow_mask, pts, 1)\n",
    "    shadow_prob = np.random.random()\n",
    "    # Apply shadow augmentation randomly to the images\n",
    "    if shadow_prob > 0.5:\n",
    "        random_shadow = 0.5\n",
    "        image_HLS[:, :, 1][shadow_mask==1] = image_HLS[:, :, 1][shadow_mask==1]*random_shadow\n",
    "    # Convert back to RGB Color model.\n",
    "    image = cv2.cvtColor(image_HLS, cv2.COLOR_HLS2RGB)\n",
    "    return image\n",
    "\n",
    "def read_image(row, index, col_index):\n",
    "        source_path = row[col_index][index]\n",
    "        filename = source_path.split('/')[-1]\n",
    "        current_path = './data/IMG/' + filename\n",
    "        image = cv2.cvtColor(cv2.imread(current_path), cv2.COLOR_BGR2RGB)\n",
    "        return image\n",
    "    \n",
    "def brightness_augment(image):\n",
    "    # Convert to the HSV colorspace first.\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    image = np.array(image, dtype = np.float64)\n",
    "    # Randomly assign the brightness value \n",
    "    brightness_random = .5 + np.random.uniform()\n",
    "    image[:,:,2] = image[:,:,2]*brightness_random\n",
    "    image[:,:,2][image[:,:,2]>255]  = 255\n",
    "    image = np.array(image, dtype = np.uint8)\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_HSV2RGB)\n",
    "    return image\n",
    "\n",
    "def crop_image(image):\n",
    "    cropped_image = image[70:135, :, :]\n",
    "    return cropped_image \n",
    "\n",
    "def normalize_image(image):\n",
    "    image.astype(np.float32)\n",
    "    image = image/255. - 0.5 \n",
    "    return image \n",
    "\n",
    "def resize_image(image, target_shape):\n",
    "    return cv2.resize(image, target_shape)\n",
    "\n",
    "def preprocess_image(image,target_shape):\n",
    "    image = crop_image(image)\n",
    "    image = resize_image(image, target_shape)\n",
    "    image = normalize_image(image)\n",
    "    return image \n",
    "\n",
    "def augmentation(row, index):\n",
    "    col_index = 0\n",
    "    cam_image = np.random.choice(['left', 'right', 'center'])\n",
    "    #print(index)\n",
    "    #print(row[3][index])\n",
    "    steering = float(row[3][index])\n",
    "    if cam_image == \"left\":\n",
    "        steering += 0.25\n",
    "        col_index = 1\n",
    "    elif cam_image == \"right\":\n",
    "        steering -= 0.25\n",
    "        col_index = 2\n",
    "    image = read_image(row, index, col_index)\n",
    "    # Flipping Augmentation\n",
    "    flip_prob = np.random.random()\n",
    "    if flip_prob > 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "        steering = -1*steering\n",
    "    # Brightness Augmentation\n",
    "    image = brightness_augment(image)\n",
    "    # Shadow Augmentation\n",
    "    image = shadow_augmentation(image)\n",
    "    # Preprocess the image \n",
    "    image = preprocess_image(image, (64, 64))\n",
    "    return image, steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Flatten, Activation, Convolution2D, Cropping2D, Lambda, Dropout, Conv2D, ELU\n",
    "from keras.models import Sequential\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    # Convolution 1st layer\n",
    "    model.add(Convolution2D(filters = 32, kernel_size = (5, 5), strides = (2, 2), padding = \"same\", input_shape = (64, 64, 3)))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.5))\n",
    "    #model.add(MaxPooling2D((2,2), padding = \"valid\"))\n",
    "    # 2nd layer\n",
    "    model.add(Convolution2D(filters = 64, kernel_size = (5, 5), strides = (2, 2), padding = \"same\", input_shape = (32, 32, 32)))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.5))\n",
    "    # 3rd layer\n",
    "    model.add(Convolution2D(filters = 128, kernel_size = (5, 5), strides = (2, 2), padding = \"same\", input_shape = (16, 16, 64)))\n",
    "    model.add(ELU())\n",
    "    model.add(Dropout(0.5))\n",
    "    # 4th layer \n",
    "#     model.add(Convolution2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = \"valid\", input_shape = (8, 8, 48)))\n",
    "#     model.add(ELU())\n",
    "#     model.add(Dropout(0.5))\n",
    "#     # 5th layer\n",
    "#     model.add(Convolution2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = \"valid\", input_shape = (6, 6, 64)))\n",
    "#     model.add(ELU())\n",
    "#     model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #model.add(Dense(1164))\n",
    "    #model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(512))\n",
    "    #model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(64))\n",
    "    #model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(10))\n",
    "    #model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1))\n",
    "    \n",
    "    model.summary()\n",
    "    model.compile(loss = \"mse\", optimizer = \"adam\")\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import sklearn\n",
    "lines = []\n",
    "with open('./data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "images = []\n",
    "measurements = []\n",
    "i = 0\n",
    "def data_generator(row, batch_size = 32):\n",
    "    N = len(row)\n",
    "    batches_per_epoch = N // batch_size\n",
    "    i = 0\n",
    "\n",
    "    while(True):\n",
    "        start = i*batch_size\n",
    "        end = start + batch_size - 1\n",
    "        # Initialize the batch data \n",
    "        X_train = np.zeros((batch_size, 64, 64, 3), dtype = np.float32)\n",
    "        y_train = np.zeros((batch_size,), dtype = np.float32)\n",
    "        for k in range(batch_size):\n",
    "                index = np.random.randint(N)\n",
    "                keep_steering_angle = 0\n",
    "                while keep_steering_angle == 0:\n",
    "                    (x, y) = augmentation(row, index)\n",
    "                    # If absolute value of steering angle smaller than 0.1, discard it with some probability.\n",
    "                    if abs(y) < 0.1:\n",
    "                        prob = np.random.uniform()\n",
    "                        # Set steer_prob_threshold depending on how many steering angles close to zero, we want to discard.\n",
    "                        if prob > steer_prob_threshold:\n",
    "                            keep_steering_angle = 1\n",
    "                    else:\n",
    "                        # If absolute value of steering angle is greater than 0.1, then we keep it.\n",
    "                        keep_steering_angle = 1\n",
    "                #print(x)\n",
    "                #plt.imshow(x, cmap = 'gray'), plt.show()\n",
    "                \n",
    "                (X_train[k], y_train[k]) = (x, y)\n",
    "        i += 1 \n",
    "        if i == batches_per_epoch - 1:\n",
    "            i = 0 \n",
    "        (X_train, y_train) = sklearn.utils.shuffle(X_train, y_train)\n",
    "        yield (X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 24)        1824      \n",
      "_________________________________________________________________\n",
      "elu_6 (ELU)                  (None, 32, 32, 24)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32, 32, 24)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 16, 16, 36)        21636     \n",
      "_________________________________________________________________\n",
      "elu_7 (ELU)                  (None, 16, 16, 36)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16, 16, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 48)          43248     \n",
      "_________________________________________________________________\n",
      "elu_8 (ELU)                  (None, 8, 8, 48)          0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 8, 8, 48)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 6, 6, 64)          27712     \n",
      "_________________________________________________________________\n",
      "elu_9 (ELU)                  (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "_________________________________________________________________\n",
      "elu_10 (ELU)                 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 100)               102500    \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 239,419\n",
      "Trainable params: 239,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/6\n",
      "156/156 [==============================] - 531s - loss: 0.3920   \n",
      "Epoch 2/6\n",
      "156/156 [==============================] - 419s - loss: 0.1165   \n",
      "Epoch 3/6\n",
      "156/156 [==============================] - 414s - loss: 0.0905   \n",
      "Epoch 4/6\n",
      " 27/156 [====>.........................] - ETA: 258s - loss: 0.0814"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-be4df931860f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20000\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mv_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m256\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#, callbacks = None,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m                     \u001b[1;31m#validation_data = validation_generator, validation_steps = v_steps)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Generator_Model.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[0;32m   1115\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m                                         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1117\u001b[1;33m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 87\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, initial_epoch)\u001b[0m\n\u001b[0;32m   1807\u001b[0m                 \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1808\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1809\u001b[1;33m                     \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1811\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    634\u001b[0m                     \u001b[1;32myield\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Let us read the data in a pandas dataframe object. And we require only the first 4 cols\n",
    "import pandas as pd\n",
    "batch_size = 128\n",
    "image_dataframe = pd.read_csv('C:/Users/lenovo/Documents/SDCND/Project-3/data/driving_log.csv', header=None, usecols = [0,1,2,3], skiprows = 1)\n",
    "(nrows, ncols) = image_dataframe.shape\n",
    "# Let us shuffle the rows of the dataframe before splitting into training and validation sets.\n",
    "image_dataframe = image_dataframe.sample(frac = 1).reset_index(drop = \"True\")\n",
    "# Let us take 80% of the data for training\n",
    "num_training_lines = int(0.8*nrows)\n",
    "training_lines = image_dataframe.loc[0:num_training_lines-1]\n",
    "validation_lines = image_dataframe.loc[num_training_lines:]\n",
    "steer_prob_threshold = 0.5\n",
    "training_generator = data_generator(training_lines, batch_size)\n",
    "validation_generator = data_generator(validation_lines, batch_size)\n",
    "\n",
    "model = get_model()\n",
    "steps_per_epoch = 20000 // batch_size\n",
    "v_steps = 256 // batch_size\n",
    "model.fit_generator(training_generator, steps_per_epoch = steps_per_epoch, epochs = 6, verbose = 1)#, callbacks = None,\n",
    "                    #validation_data = validation_generator, validation_steps = v_steps)\n",
    "model.save(\"Generator_Model.h5\")\n",
    "model.save_weights(\"Generator_Model_Weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering\n"
     ]
    }
   ],
   "source": [
    "print(training_lines[3][4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
