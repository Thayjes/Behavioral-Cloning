{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt \n",
    "# Here we will define the function for preprocessing and augmentation\n",
    "def shadow_augmentation(image):\n",
    "    # Let us randomly define the quadrilateral where we want to apply the shadow \n",
    "    pt1 = np.array([np.random.choice([0, image.shape[1]]), 0])\n",
    "    pt2 = np.array([pt1[0], image.shape[0]])\n",
    "    pt3 = np.array([np.random.randint(0, image.shape[0]//2), image.shape[0]])\n",
    "    pt4 = np.array([np.random.randint(0, image.shape[0]//2), 0])\n",
    "    pts = np.array([pt1, pt2, pt3, pt4])\n",
    "    #print(pts)\n",
    "    # Convert the image to Hue, Lightness, Saturation color model.\n",
    "    image_HLS = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    # Initialize the mask\n",
    "    shadow_mask = 0*image_HLS[:, :, 1]\n",
    "    # Now fill the quadrilateral as defined before\n",
    "    shadow_mask = cv2.fillConvexPoly(shadow_mask, pts, 1)\n",
    "    shadow_prob = np.random.random()\n",
    "    # Apply shadow augmentation randomly to the images\n",
    "    if shadow_prob > 0.5:\n",
    "        random_shadow = 0.5\n",
    "        image_HLS[:, :, 1][shadow_mask==1] = image_HLS[:, :, 1][shadow_mask==1]*random_shadow\n",
    "    # Convert back to RGB Color model.\n",
    "    image = cv2.cvtColor(image_HLS, cv2.COLOR_HLS2RGB)\n",
    "    return image\n",
    "\n",
    "def read_image(row, index, col_index):\n",
    "        source_path = row[col_index][index]\n",
    "        filename = source_path.split('/')[-1]\n",
    "        current_path = './data/IMG/' + filename\n",
    "        image = cv2.cvtColor(cv2.imread(current_path), cv2.COLOR_BGR2RGB)\n",
    "        return image\n",
    "    \n",
    "def brightness_augment(image):\n",
    "    # Convert to the HSV colorspace first.\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    image = np.array(image, dtype = np.float64)\n",
    "    # Randomly assign the brightness value \n",
    "    brightness_random = .5 + np.random.uniform()\n",
    "    image[:,:,2] = image[:,:,2]*brightness_random\n",
    "    image[:,:,2][image[:,:,2]>255]  = 255\n",
    "    image = np.array(image, dtype = np.uint8)\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_HSV2RGB)\n",
    "    return image\n",
    "\n",
    "def crop_image(image):\n",
    "    cropped_image = image[50:135, :, :]\n",
    "    return cropped_image \n",
    "\n",
    "def normalize_image(image):\n",
    "    image.astype(np.float32)\n",
    "    image = image/255. - 0.5 \n",
    "    return image \n",
    "\n",
    "def resize_image(image, target_shape):\n",
    "    return cv2.resize(image, target_shape)\n",
    "\n",
    "def preprocess_image(image,target_shape):\n",
    "    image = crop_image(image)\n",
    "    image = resize_image(image, target_shape)\n",
    "    image = normalize_image(image)\n",
    "    return image \n",
    "\n",
    "def augmentation(row, index):\n",
    "    col_index = 0\n",
    "    cam_image = np.random.choice(['left', 'right', 'center'])\n",
    "    #print(index)\n",
    "    #print(row[3][index])\n",
    "    steering = float(row[3][index])\n",
    "    if cam_image == \"left\":\n",
    "        steering += 0.25\n",
    "        col_index = 1\n",
    "    elif cam_image == \"right\":\n",
    "        steering -= 0.25\n",
    "        col_index = 2\n",
    "    image = read_image(row, index, col_index)\n",
    "    # Flipping Augmentation\n",
    "    flip_prob = np.random.random()\n",
    "    if flip_prob > 0.5:\n",
    "        image = cv2.flip(image, 1)\n",
    "        steering = -1*steering\n",
    "    # Brightness Augmentation\n",
    "    image = brightness_augment(image)\n",
    "    # Shadow Augmentation\n",
    "    image = shadow_augmentation(image)\n",
    "    # Preprocess the image \n",
    "    image = preprocess_image(image, (64, 64))\n",
    "    return image, steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Dense, Flatten, Activation, Convolution2D, Cropping2D, Lambda, Dropout, Conv2D, ELU, MaxPooling2D\n",
    "# from keras.models import Sequential\n",
    "# def get_model():\n",
    "#     model = Sequential()\n",
    "#     # Convolution 1st layer\n",
    "#     model.add(Convolution2D(filters = 32, kernel_size = (5, 5), strides = (2, 2), padding = \"same\", input_shape = (64, 64, 3)))\n",
    "#     model.add(ELU())\n",
    "#     model.add(MaxPooling2D((2, 2), padding = \"valid\"))\n",
    "#     model.add(Dropout(0.5))\n",
    "    \n",
    "#     # 2nd layer\n",
    "#     model.add(Convolution2D(filters = 64, kernel_size = (5, 5), strides = (2, 2), padding = \"same\", input_shape = (16, 16, 32)))\n",
    "#     model.add(ELU())\n",
    "#     model.add(MaxPooling2D((2, 2), padding = \"valid\"))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     # 3rd layer\n",
    "#     model.add(Convolution2D(filters = 128, kernel_size = (5, 5), strides = (2, 2), padding = \"same\", input_shape = (8, 8, 64)))\n",
    "#     model.add(ELU())\n",
    "#     model.add(MaxPooling2D((2, 2), padding = \"valid\"))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     # 4th layer \n",
    "# #     model.add(Convolution2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = \"valid\", input_shape = (8, 8, 48)))\n",
    "# #     model.add(ELU())\n",
    "# #     model.add(Dropout(0.5))\n",
    "# #     # 5th layer\n",
    "# #     model.add(Convolution2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = \"valid\", input_shape = (6, 6, 64)))\n",
    "# #     model.add(ELU())\n",
    "# #     model.add(Dropout(0.5))\n",
    "    \n",
    "#     model.add(Flatten())\n",
    "    \n",
    "#     #model.add(Dense(1164))\n",
    "#     #model.add(Dropout(0.5))\n",
    "    \n",
    "#     model.add(Dense(512))\n",
    "#     #model.add(ELU())\n",
    "#     #model.add(Dropout(0.5))\n",
    "    \n",
    "#     model.add(Dense(64))\n",
    "#     #model.add(ELU())\n",
    "#     #model.add(Dropout(0.5))\n",
    "    \n",
    "#     model.add(Dense(10))\n",
    "#     #model.add(Dropout(0.5))\n",
    "    \n",
    "#     model.add(Dense(1))\n",
    "    \n",
    "#     model.summary()\n",
    "#     model.compile(loss = \"mse\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "#     return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Activation, Convolution2D, Cropping2D, Lambda, Dropout, Conv2D, ELU, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "adam = optimizers.Adam(lr = 0.0001)\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    #Layer 1\n",
    "    # Output of layer 1 is 64x64x3\n",
    "    model.add(Convolution2D(filters = 3, kernel_size = (1, 1), strides = (1, 1), input_shape = (64, 64, 3), activation = \"elu\", padding = \"same\"))\n",
    "    \n",
    "    #Layer 2\n",
    "    # Output of layer 2 is : \n",
    "    model.add(Convolution2D(filters = 32, kernel_size = (3,3), strides=(1,1), activation = 'elu', padding = \"same\"))\n",
    "    model.add(Convolution2D(filters = 32, kernel_size = (3,3), strides=(1,1), activation = 'elu', padding = \"same\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #Layer 3\n",
    "    # Output of layer 3 is \n",
    "    model.add(Convolution2D(64, (3,3) ,strides=(1,1),activation='elu', padding = \"same\"))\n",
    "    model.add(Convolution2D(64, (3,3) ,strides=(1,1),activation='elu', padding = \"same\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    #Layer 4\n",
    "    # Output of layer 4 is \n",
    "    model.add(Convolution2D(128, (3,3) ,strides=(1,1),activation='elu', padding = \"same\"))\n",
    "    model.add(Convolution2D(128, (3,3) ,strides=(1,1),activation='elu', padding = \"same\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    #Layer 6\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('elu'))\n",
    "\n",
    "    #Layer 7\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('elu'))\n",
    "\n",
    "    #Layer 8\n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('elu'))\n",
    "\n",
    "    #Layer 9\n",
    "    model.add(Dense(1))\n",
    "    model.summary()\n",
    "    model.compile(loss='mse',optimizer= \"adam\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import sklearn\n",
    "lines = []\n",
    "with open('./data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "\n",
    "images = []\n",
    "measurements = []\n",
    "i = 0\n",
    "def data_generator(row, batch_size = 32):\n",
    "    N = len(row)\n",
    "    batches_per_epoch = N // batch_size\n",
    "    i = 0\n",
    "\n",
    "    while(True):\n",
    "        start = i*batch_size\n",
    "        end = start + batch_size - 1\n",
    "        # Initialize the batch data \n",
    "        X_train = np.zeros((batch_size, 64, 64, 3), dtype = np.float32)\n",
    "        y_train = np.zeros((batch_size,), dtype = np.float32)\n",
    "        for k in range(batch_size):\n",
    "                index = np.random.randint(N)\n",
    "                #print(N)\n",
    "                keep_steering_angle = 0\n",
    "                while keep_steering_angle == 0:\n",
    "                    (x, y) = augmentation(row, index)\n",
    "                    # If absolute value of steering angle smaller than 0.1, discard it with some probability.\n",
    "                    if abs(y) < 0.1:\n",
    "                        prob = np.random.uniform()\n",
    "                        # Set steer_prob_threshold depending on how many steering angles close to zero, we want to discard.\n",
    "                        if prob > steer_prob_threshold:\n",
    "                            keep_steering_angle = 1\n",
    "                    else:\n",
    "                        # If absolute value of steering angle is greater than 0.1, then we keep it.\n",
    "                        keep_steering_angle = 1\n",
    "                #print(x)\n",
    "                #plt.imshow(x, cmap = 'gray'), plt.show()\n",
    "                \n",
    "                (X_train[k], y_train[k]) = (x, y)\n",
    "        i += 1 \n",
    "        if i == batches_per_epoch - 1:\n",
    "            i = 0 \n",
    "        (X_train, y_train) = sklearn.utils.shuffle(X_train, y_train)\n",
    "        yield (X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 64, 64, 3)         12        \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                1040      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 4,515,725\n",
      "Trainable params: 4,515,725\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1\n",
      "625/625 [==============================] - 1012s - loss: 0.1907 - val_loss: 1.3619\n"
     ]
    }
   ],
   "source": [
    "# Let us read the data in a pandas dataframe object. And we require only the first 4 cols\n",
    "import pandas as pd\n",
    "from keras.callbacks import History, Callback\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs = {}):\n",
    "        self.training_loss = []\n",
    "        self.training_acc = []\n",
    "        self.validation_loss = []\n",
    "        self.validation_acc = []\n",
    "    def on_epoch_end(self, epoch, logs = {}):\n",
    "        self.training_loss.append(logs.get('loss'))\n",
    "        self.validation_loss.append(logs.get('val_loss'))\n",
    "        self.training_acc.append(logs.get('acc'))\n",
    "        self.validation_acc.append(logs.get('val_acc'))\n",
    "        \n",
    "history = LossHistory()\n",
    "batch_size = 32\n",
    "nb_epochs = 1\n",
    "image_dataframe = pd.read_csv('C:/Users/lenovo/Documents/SDCND/Project-3/data/driving_log.csv', header=None, usecols = [0,1,2,3], skiprows = 1)\n",
    "(nrows, ncols) = image_dataframe.shape\n",
    "# Let us shuffle the rows of the dataframe before splitting into training and validation sets.\n",
    "image_dataframe = image_dataframe.sample(frac = 1).reset_index(drop = \"True\")\n",
    "# Let us take 80% of the data for training\n",
    "num_training_lines = int(0.8*nrows)\n",
    "training_lines = image_dataframe.loc[0:num_training_lines-1]\n",
    "validation_lines = image_dataframe.loc[num_training_lines:]\n",
    "steer_prob_threshold = 0.5\n",
    "validation_lines = validation_lines.sample(frac=1).reset_index(drop = \"True\")\n",
    "training_generator = data_generator(training_lines, batch_size)\n",
    "validation_generator = data_generator(validation_lines, batch_size)\n",
    "model = get_model()\n",
    "steps_per_epoch = 20000 // batch_size\n",
    "v_steps = 20000 // batch_size\n",
    "model.fit_generator(training_generator, steps_per_epoch = steps_per_epoch, epochs = nb_epochs, verbose = 1, callbacks = [history], validation_data = validation_generator, validation_steps = v_steps)\n",
    "model.save(\"Generator_Model.h5\")\n",
    "model.save_weights(\"Generator_Model_Weights.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x130abffb6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.legend.Legend at 0x130ab94c588>, None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the loss vs epochs.\n",
    "plt.figure(1)\n",
    "plt.title(\"Comparison of training and validation loss\")\n",
    "plt.plot(range(1, nb_epochs+1), history.training_loss, 'r-x', label = \"Training Loss\")\n",
    "plt.plot(range(1, nb_epochs+1), history.validation_loss, 'b-x', label = \"Validation Loss\")\n",
    "plt.ylabel(\"Loss\"), plt.xlabel(\"Epochs\")\n",
    "plt.legend(loc = \"upper right\"), plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "print (keras.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
